atari:
  env_wrapper:
    - utils.wrappers.AtariWrapper
  policy: 'CnnPolicy'
  n_timesteps: !!float 1e7
  buffer_size: 1000000
  learning_rate: !!float 1e-4
  learning_starts: !!float 1e5
  target_update_interval: 1000
  train_freq: 4
  exploration_final_eps: 0.01


CartPole-v1:
  #normalize: True
  n_timesteps: !!float 2e4
  policy: 'MlpPolicy'
  learning_rate: !!float 1e-4
  batch_size: 256
  buffer_size: 20000
  exploration_final_eps: 0.02

MountainCar-v0:
  normalize: True
  n_timesteps: 100000
  policy: 'MlpPolicy'
  learning_rate: !!float 1e-4
  buffer_size: 30000
  exploration_final_eps: 0.1

LunarLander-v2:
  n_timesteps: !!float 1e5
  policy: 'MlpPolicy'
  learning_rate: !!float 1e-4
  buffer_size: 50000
  exploration_final_eps: 0.05

Acrobot-v1:
  normalize: True
  n_timesteps: !!float 1e5
  policy: 'MlpPolicy'
  learning_rate: !!float 1e-4
  buffer_size: 50000
  exploration_final_eps: 0.02
